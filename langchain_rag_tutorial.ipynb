{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62667738",
   "metadata": {},
   "source": [
    "# Notebook - LangChain RAG Tutorial\n",
    "\n",
    "**Escuela Colombiana de Ingeniería Julio Garavito**\n",
    "\n",
    "**Student:** Santiago Botero García\n",
    "\n",
    "## Step 0: Setup & Imports\n",
    "\n",
    "This notebook demonstrates a **Retrieval-Augmented Generation (RAG)** pipeline using LangChain,\n",
    "with support for **OpenAI** and **Google Gemini** as interchangeable LLM providers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5835bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in .\\.venv\\Lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: langchain-classic in .\\.venv\\Lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: langchain-text-splitters in .\\.venv\\Lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: langchain-community in .\\.venv\\Lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: langchain-openai in .\\.venv\\Lib\\site-packages (1.1.9)\n",
      "Requirement already satisfied: langchain-google-genai in .\\.venv\\Lib\\site-packages (4.2.0)\n",
      "Requirement already satisfied: bs4 in .\\.venv\\Lib\\site-packages (0.0.2)\n",
      "Requirement already satisfied: chromadb in .\\.venv\\Lib\\site-packages (1.5.0)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.2.1 in .\\.venv\\Lib\\site-packages (from langchain) (1.2.12)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in .\\.venv\\Lib\\site-packages (from langchain) (1.0.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in .\\.venv\\Lib\\site-packages (from langchain) (2.12.5)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in .\\.venv\\Lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in .\\.venv\\Lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (0.7.3)\n",
      "Requirement already satisfied: packaging>=23.2.0 in .\\.venv\\Lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (26.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in .\\.venv\\Lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in .\\.venv\\Lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (9.1.4)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in .\\.venv\\Lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in .\\.venv\\Lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in .\\.venv\\Lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.1->langchain) (3.0.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in .\\.venv\\Lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (4.0.0)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.7 in .\\.venv\\Lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.7)\n",
      "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in .\\.venv\\Lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.3.5)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in .\\.venv\\Lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in .\\.venv\\Lib\\site-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.2)\n",
      "Requirement already satisfied: httpx>=0.25.2 in .\\.venv\\Lib\\site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in .\\.venv\\Lib\\site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (3.11.7)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in .\\.venv\\Lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in .\\.venv\\Lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in .\\.venv\\Lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (0.25.0)\n",
      "Requirement already satisfied: anyio in .\\.venv\\Lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (4.12.1)\n",
      "Requirement already satisfied: certifi in .\\.venv\\Lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in .\\.venv\\Lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in .\\.venv\\Lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in .\\.venv\\Lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in .\\.venv\\Lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in .\\.venv\\Lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in .\\.venv\\Lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Requirement already satisfied: sqlalchemy<3.0.0,>=1.4.0 in .\\.venv\\Lib\\site-packages (from langchain-classic) (2.0.46)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in .\\.venv\\Lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in .\\.venv\\Lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (2.6.3)\n",
      "Requirement already satisfied: greenlet>=1 in .\\.venv\\Lib\\site-packages (from sqlalchemy<3.0.0,>=1.4.0->langchain-classic) (3.3.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in .\\.venv\\Lib\\site-packages (from langchain-community) (3.13.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in .\\.venv\\Lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in .\\.venv\\Lib\\site-packages (from langchain-community) (2.12.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in .\\.venv\\Lib\\site-packages (from langchain-community) (0.4.3)\n",
      "Requirement already satisfied: numpy>=1.26.2 in .\\.venv\\Lib\\site-packages (from langchain-community) (2.4.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in .\\.venv\\Lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in .\\.venv\\Lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in .\\.venv\\Lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in .\\.venv\\Lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in .\\.venv\\Lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in .\\.venv\\Lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in .\\.venv\\Lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in .\\.venv\\Lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in .\\.venv\\Lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in .\\.venv\\Lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in .\\.venv\\Lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: openai<3.0.0,>=1.109.1 in .\\.venv\\Lib\\site-packages (from langchain-openai) (2.21.0)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in .\\.venv\\Lib\\site-packages (from langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in .\\.venv\\Lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in .\\.venv\\Lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.13.0)\n",
      "Requirement already satisfied: sniffio in .\\.venv\\Lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in .\\.venv\\Lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in .\\.venv\\Lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2026.1.15)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in .\\.venv\\Lib\\site-packages (from langchain-google-genai) (1.2.0)\n",
      "Requirement already satisfied: google-genai<2.0.0,>=1.56.0 in .\\.venv\\Lib\\site-packages (from langchain-google-genai) (1.63.0)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.47.0 in .\\.venv\\Lib\\site-packages (from google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (2.48.0)\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in .\\.venv\\Lib\\site-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (15.0.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in .\\.venv\\Lib\\site-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (0.4.2)\n",
      "Requirement already satisfied: cryptography>=38.0.3 in .\\.venv\\Lib\\site-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (46.0.5)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in .\\.venv\\Lib\\site-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in .\\.venv\\Lib\\site-packages (from rsa<5,>=3.1.4->google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (0.6.2)\n",
      "Requirement already satisfied: beautifulsoup4 in .\\.venv\\Lib\\site-packages (from bs4) (4.14.3)\n",
      "Requirement already satisfied: build>=1.0.3 in .\\.venv\\Lib\\site-packages (from chromadb) (1.4.0)\n",
      "Requirement already satisfied: pybase64>=1.4.1 in .\\.venv\\Lib\\site-packages (from chromadb) (1.4.3)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in .\\.venv\\Lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.40.0)\n",
      "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in .\\.venv\\Lib\\site-packages (from chromadb) (5.4.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in .\\.venv\\Lib\\site-packages (from chromadb) (1.24.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in .\\.venv\\Lib\\site-packages (from chromadb) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in .\\.venv\\Lib\\site-packages (from chromadb) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in .\\.venv\\Lib\\site-packages (from chromadb) (1.39.1)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in .\\.venv\\Lib\\site-packages (from chromadb) (0.22.2)\n",
      "Requirement already satisfied: pypika>=0.48.9 in .\\.venv\\Lib\\site-packages (from chromadb) (0.51.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in .\\.venv\\Lib\\site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in .\\.venv\\Lib\\site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in .\\.venv\\Lib\\site-packages (from chromadb) (1.78.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in .\\.venv\\Lib\\site-packages (from chromadb) (5.0.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in .\\.venv\\Lib\\site-packages (from chromadb) (0.23.1)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in .\\.venv\\Lib\\site-packages (from chromadb) (35.0.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in .\\.venv\\Lib\\site-packages (from chromadb) (5.2.0)\n",
      "Requirement already satisfied: rich>=10.11.0 in .\\.venv\\Lib\\site-packages (from chromadb) (14.3.2)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in .\\.venv\\Lib\\site-packages (from chromadb) (4.26.0)\n",
      "Requirement already satisfied: six>=1.5 in .\\.venv\\Lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in .\\.venv\\Lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in .\\.venv\\Lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: pyproject_hooks in .\\.venv\\Lib\\site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: colorama in .\\.venv\\Lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Requirement already satisfied: cffi>=2.0.0 in .\\.venv\\Lib\\site-packages (from cryptography>=38.0.3->google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (2.0.0)\n",
      "Requirement already satisfied: pycparser in .\\.venv\\Lib\\site-packages (from cffi>=2.0.0->cryptography>=38.0.3->google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in .\\.venv\\Lib\\site-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in .\\.venv\\Lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.25.0 in .\\.venv\\Lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.30.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in .\\.venv\\Lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: requests-oauthlib in .\\.venv\\Lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in .\\.venv\\Lib\\site-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
      "Requirement already satisfied: flatbuffers in .\\.venv\\Lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (25.12.19)\n",
      "Requirement already satisfied: protobuf in .\\.venv\\Lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (6.33.5)\n",
      "Requirement already satisfied: sympy in .\\.venv\\Lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in .\\.venv\\Lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.1)\n",
      "Requirement already satisfied: zipp>=3.20 in .\\.venv\\Lib\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in .\\.venv\\Lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.72.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.39.1 in .\\.venv\\Lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-proto==1.39.1 in .\\.venv\\Lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.60b1 in .\\.venv\\Lib\\site-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.60b1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in .\\.venv\\Lib\\site-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in .\\.venv\\Lib\\site-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in .\\.venv\\Lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in .\\.venv\\Lib\\site-packages (from tokenizers>=0.13.2->chromadb) (1.4.1)\n",
      "Requirement already satisfied: filelock in .\\.venv\\Lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.21.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in .\\.venv\\Lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2026.2.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in .\\.venv\\Lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.2.0)\n",
      "Requirement already satisfied: shellingham in .\\.venv\\Lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in .\\.venv\\Lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (0.23.1)\n",
      "Requirement already satisfied: click>=8.0.0 in .\\.venv\\Lib\\site-packages (from typer>=0.9.0->chromadb) (8.3.1)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in .\\.venv\\Lib\\site-packages (from typer>=0.9.0->chromadb) (0.0.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in .\\.venv\\Lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.7.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in .\\.venv\\Lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
      "Requirement already satisfied: soupsieve>=1.6.1 in .\\.venv\\Lib\\site-packages (from beautifulsoup4->bs4) (2.8.3)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in .\\.venv\\Lib\\site-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in .\\.venv\\Lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain langchain-classic langchain-text-splitters langchain-community langchain-openai langchain-google-genai bs4 chromadb\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from bs4.filter import SoupStrainer\n",
    "from langchain_classic.chains import RetrievalQA\n",
    "from langchain_openai import OpenAI as OpenAI_LLM\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI as Gemini_LLM\n",
    "from langchain.tools import tool\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f755b16",
   "metadata": {},
   "source": [
    "## Step 0: API Key Detection\n",
    "\n",
    "The pipeline automatically detects which LLM provider is available\n",
    "based on environment variables:\n",
    "\n",
    "- `OPENAI_API_KEY` &rarr; OpenAI\n",
    "- `GOOGLE_API_KEY` &rarr; Gemini\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "75f5a7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Using provider: gemini\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "LLM_PROVIDER = None\n",
    "\n",
    "if os.getenv(\"OPENAI_API_KEY\"):\n",
    "    LLM_PROVIDER = \"openai\"\n",
    "elif os.getenv(\"GOOGLE_API_KEY\"):\n",
    "    LLM_PROVIDER = \"gemini\"\n",
    "else:\n",
    "    raise RuntimeError(\"No API key found (OPENAI_API_KEY or GOOGLE_API_KEY required)\")\n",
    "\n",
    "print(f\"[+] Using provider: {LLM_PROVIDER}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f629be98",
   "metadata": {},
   "source": [
    "## Step 1: Load and Chunk Documents\n",
    "\n",
    "### Web Document Loading\n",
    "\n",
    "External web content is loaded and split into overlapping chunks\n",
    "to optimize embedding quality and semantic retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fe36bc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs={\n",
    "        \"parse_only\": SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee27a0ba",
   "metadata": {},
   "source": [
    "### Loading Documents into Memory\n",
    "\n",
    "The webpage content is loaded and normalized into LangChain’s `Document` format, which includes:\n",
    "\n",
    "* `page_content` (the text)\n",
    "* `metadata` (source URL and other attributes)\n",
    "\n",
    "This abstraction allows downstream components (splitters, vector stores, retrievers) to work consistently across different data sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2c088cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Loaded 1 docs — characters: 43047\n"
     ]
    }
   ],
   "source": [
    "docs = loader.load()\n",
    "print(f\"[+] Loaded {len(docs)} docs — characters: {len(docs[0].page_content)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6349bb",
   "metadata": {},
   "source": [
    "### Text Chunking\n",
    "\n",
    "Large documents are split into smaller overlapping chunks to optimize retrieval and embedding quality.\n",
    "\n",
    "* `chunk_size=1000` ensures each chunk fits comfortably within model context limits.\n",
    "* `chunk_overlap=200` preserves semantic continuity between chunks.\n",
    "* The recursive strategy attempts to split on natural boundaries (paragraphs, sentences) when possible.\n",
    "\n",
    "This step reflects the RAG principle that **retrieval happens at the chunk level, not the document level**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6a20608a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Split into 63 chunks\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "\n",
    "splits = text_splitter.split_documents(docs)\n",
    "print(f\"[+] Split into {len(splits)} chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96cca7d",
   "metadata": {},
   "source": [
    "## Step 2: Vector Store & Retrieval Setup\n",
    "\n",
    "This section introduces the components responsible for semantic search:\n",
    "\n",
    "* `OpenAIEmbeddings` converts text chunks into high-dimensional vectors.\n",
    "* `Chroma` is a lightweight, local vector database used to store and search those embeddings.\n",
    "\n",
    "LangChain’s RAG tutorial highlights that vector stores are **pluggable**, and Chroma is used here for simplicity and fast prototyping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f11dd6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if LLM_PROVIDER == \"openai\":\n",
    "    from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "    embeddings = OpenAIEmbeddings(\n",
    "        model=\"text-embedding-3-large\"\n",
    "    )\n",
    "\n",
    "    llm = ChatOpenAI(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "elif LLM_PROVIDER == \"gemini\":\n",
    "    from langchain_google_genai import (\n",
    "        ChatGoogleGenerativeAI,\n",
    "        GoogleGenerativeAIEmbeddings\n",
    "    )\n",
    "\n",
    "    embeddings = GoogleGenerativeAIEmbeddings(\n",
    "        model=\"gemini-embedding-001\"\n",
    "    )\n",
    "\n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-2.5-flash-lite\",\n",
    "        temperature=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748f404a",
   "metadata": {},
   "source": [
    "### Creating Embeddings and Vector Store\n",
    "\n",
    "* Each text chunk is embedded using an OpenAI embedding model.\n",
    "* The embeddings are stored in Chroma, enabling similarity-based retrieval.\n",
    "* This forms the knowledge base that the RAG system will query at runtime.\n",
    "\n",
    "At this point, the pipeline has transformed raw web content into a searchable semantic index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a84f66ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Vector store created\n"
     ]
    }
   ],
   "source": [
    "vector_store = Chroma.from_documents(\n",
    "    splits,\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "print(\"[+] Vector store created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2407539f",
   "metadata": {},
   "source": [
    "## Step 3: RAG Tool for the Retrieval Chain\n",
    "\n",
    "Retrieval is exposed as a LangChain tool so the Retrieval Chain can explicitly\n",
    "query the vector store when needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8d18cd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def retrieve_context(query: str) -> str:\n",
    "    \"\"\"Retrieve relevant document chunks from the vector store.\"\"\"\n",
    "    docs = vector_store.similarity_search(query, k=4)\n",
    "    return \"\\n\\n\".join(d.page_content for d in docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262194a4",
   "metadata": {},
   "source": [
    "## Step 4: Create the Retrieval Chain\n",
    "\n",
    "The system prompt defines the Retrieval Chain’s role and behavior.\n",
    "\n",
    "* It explicitly instructs the Retrieval Chain to rely on retrieval rather than hallucation.\n",
    "* This aligns with LangChain’s recommendation to **steer Retrieval Chain behavior via prompts**, not just code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b839af",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    \"You are a retrieval-augmented generation Retrieval Chain. \"\n",
    "    \"Use the provided retrieval tool to answer user queries.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffb6b8f",
   "metadata": {},
   "source": [
    "This creates a LangChain Retrieval Chain that:\n",
    "\n",
    "* Uses the default chat model configured via environment variables\n",
    "* Has access to the retrieval tool\n",
    "* Can reason about when to call the tool versus when to answer directly\n",
    "\n",
    "This is the core orchestration layer of the RAG system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fe4bb5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Retrieval Chain created (multi-provider compatible)\n"
     ]
    }
   ],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=vector_store.as_retriever(),\n",
    ")\n",
    "\n",
    "print(\"[+] Retrieval Chain created (multi-provider compatible)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971fb061",
   "metadata": {},
   "source": [
    "## Step 5: Running the Retrieval Chain\n",
    "\n",
    "A sample user query is provided to demonstrate the full RAG loop:\n",
    "\n",
    "1. The Retrieval Chain receives the question\n",
    "2. It invokes the retrieval tool\n",
    "3. Retrieved context is injected\n",
    "4. The final answer is generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9204679a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is task decomposition?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfbc7d6",
   "metadata": {},
   "source": [
    "The Retrieval Chain is executed in streaming mode, allowing you to observe intermediate reasoning and tool usage step by step.\n",
    "\n",
    "This reflects the LangChain tutorial’s focus on **inspectability and transparency**, making RAG systems easier to debug and understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "84221c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task decomposition is the process of breaking down a larger task into smaller, more manageable sub-tasks or sub-goals. This can be achieved in several ways:\n",
      "\n",
      "*   **By LLM with simple prompting:** This involves using straightforward prompts like \"Steps for XYZ.\\n1.\" or \"What are the subgoals for achieving XYZ?\".\n",
      "*   **By using task-specific instructions:** For example, providing a prompt like \"Write a story outline.\" for the task of writing a novel.\n",
      "*   **With human inputs:** Direct human guidance can also be used to decompose tasks.\n",
      "\n",
      "A distinct approach, known as **LLM+P**, involves using an external classical planner for long-horizon planning. This method uses the Planning Domain Definition Language (PDDL) as an intermediary. The process involves:\n",
      "1.  The LLM translating the problem into \"Problem PDDL\".\n",
      "2.  Requesting a classical planner to generate a PDDL plan based on an existing \"Domain PDDL\".\n",
      "3.  The LLM translating the PDDL plan back into natural language.\n",
      "\n",
      "Essentially, LLM+P outsources the planning step to an external tool, which requires the availability of domain-specific PDDL and a suitable planner. This is common in certain robotic setups but not in many other domains.\n"
     ]
    }
   ],
   "source": [
    "response = qa_chain.run(query)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
